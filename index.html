
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
    <link
    rel="shortcut icon"
    sizes="16x16 32x32 64x64"
    href="./pictures/icon_head.jpeg"
    />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <style type="text/css" media="all">
      body {font-family: 'Droid Sans', helvetica,Arial,sans-serif;}
      a:link, a:visited, a:active {text-decoration:none}
      div.container{width:80%; margin:2%; line-height:140%;}
      div.right{float:right;width:200px; margin:1em; padding:1em;}
      div.content{margin-left:4%; padding:1em;}
      div.foo p {margin-bottom:0.0em; margin-top:0.0em;}
    </style>

    <title>Xiaoyu Lu</title> 
    <meta name="description" content="Personal page of Xiaoyu Lu.">
    <meta name="keywords" content="Machine learning, Statistical modelling">
    <meta name="resource-type" content="document">
    <meta name="distribution" content="global">
    <meta http-equiv="Content-Style-Type" content="text/css">

    <script type="text/javascript" async="" src="www.google-analytics.com/ga.js">
    </script>
    <script type="text/javascript">
        function trackOutboundLink(link, category, action) { 
            try { 
            _gaq.push(['_trackEvent', category , action]); 
            } catch(err){}
        }
    </script>

    <script type="text/javascript">
      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-8635368-2']);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
    </script>
  </head>

  <body>
    <br>
    <div class="container">
      <div class="right"><img alt="" width="250px" src="./pictures/profile.jpeg"></div>
      <div class="content">
        <h1 style="text-align: left;">Xiaoyu Lu</h1>

        <b><font size="4">
          <a href="#publications" onclick="_gaq.push(['_trackEvent', 'withinpage', 'publications', 'textlink']);">Publications</a>
          </font>
        </b>

        <br>
        <br>

        <p>
          I'm a machine learning scientist at Amazon, working on various topics in Machine Learning/Statistical Modelling. Recently I have been working on explainable models to emulate complicated supply chain systems. I am proficient with Python, AWS tools including cloud computing, SageMaker, State Machine etc.. I am also familiar with data analytics tools such as data pipelines and SQL. Prior to Amazon I did my PhD in probabilistic machine learning at <a href="http://www.ox.ac.uk/">University of Oxford</a>, supervised by <a href="http://www.stats.ox.ac.uk/~teh/">Prof. Yee Whye Teh</a> in the <a href="http://csml.stats.ox.ac.uk/">Machine Learning group</a> at the <a href="http://stats.ox.ac.uk/"> Department of Statistics</a>, with research experience in generative models, Gaussian Processes, MCMC, Bayesian inference, deep learning, recommender systems, and reinforcement learning. Before my PhD, I did my undergraduate in Mathematics and Statistics at <a href="https://www.ox.ac.uk/">University of Oxford</a> with the MMath degree, during which I have topped the department in both the bachelor (3rd year) and the master year (4th year). My fourth year thesis is on Recommender System for movie recommendations using collaborative filtering. 
        </p>
        <p> 
          I spent a summer at <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-cambridge/">Microsoft Research, Cambridge</a> as a research intern, and worked on a reinforcement learning project. Specifically, we use a latent variable model in imitation learning to learn different playstyles in games.  
          I also interned at Amazon working on Bayesian Optimisation in non-Euclidean spaces. 
          I have also enjoyed my internships working as a Quantitative Researcher in the financial industry, where I worked on model validation and financial derivative pricing models.
        </p>
        <p>
          <a href="./cv/CV_Xiaoyu.pdf" onclick="_gaq.push(['_trackEvent', 'downloads', 'resume', 'pdf']);">Curriculum Vitae</a> (last updated: Feb 2023)
        </p>
        <p>
          <a href="https://scholar.google.com/citations?hl=en&user=ELqAe3MAAAAJ">Google scholar page</a>
        </p>
          
        <p> 
          LinkedIn: <a href="https://www.linkedin.com/in/xiaoyu-l-a449616b/">LinkedIn</a>
        </p>
        
          <p> 
        Personal E-mail: <a href="mailto:luxiaoyu644@google.com">luxiaoyu644@google.com;</a>
        Work E-mail: <a href="mailto:luxiaoyu@amazon.com">luxiaoyu@amazon.com</a>
        </p>

        <div class="foo">
          <!-- Recent -->
            
          <H2><a id="publications">Publications</a></H2>
          <table border="0" cellspacing="10" cellpadding="2">
            <tbody>
              <tr>
                <td valign="top">
                  <b>Daisee: Adaptive Importance Sampling by Balancing Exploration and Exploitation</b>
                  <p>
                  <em>Abstract:</em> We study adaptive importance sampling (AIS) as an online learning problem and argue for the importance of the trade- off between exploration and exploitation in this adaptation. Borrowing ideas from the online learning literature, we pro- pose Daisee, a partition-based AIS algorithm. We further
                  introduce a notion of regret for AIS and show that Daisee has O(√T(logT)^(3/4)) cumulative pseudo-regret, where T is the number of iterations. We then extend Daisee to adap- tively learn a hierarchical partitioning of the sample space for more efficient sampling and confirm the performance of both algorithms empirically.
                  
                  </p>
                  <a href="./index.html" onclick="trackOutboundLink(this, 'outbound', 'Xiaoyu');">Xiaoyu Lu</a>,
                  <a href="https://www.robots.ox.ac.uk/~twgr/" onclick="trackOutboundLink(this, 'outbound', 'Tom');">Tom Rainforth</a>,
                  <a href="http://www.stats.ox.ac.uk/~teh/" onclick="trackOutboundLink(this, 'outbound', 'Yee Whye');">Yee Whye Teh</a>
              <br>
                  <em><b>Scandinavian Journal of Statistics 2023.</b></em><br>
                  <br>
                </td>
              </tr>
                 <tr>
                  <td valign="top">
                    <b>Additive Gaussian Processes Revisited</b>
                    <p>
                    <em>Abstract:</em> Gaussian Process (GP) models are a class of flexible non-parametric models that have rich representational power. By using a Gaussian process with additive structure, complex responses can be modelled whilst retaining interpretability. Previous work showed that additive Gaussian
                    process models require high-dimensional interaction terms. We propose the orthogonal additive
                    kernel (OAK), which imposes an orthogonality
                    constraint on the additive functions, enabling an
                    identifiable, low-dimensional representation of
                    the functional relationship. We connect the OAK
                    kernel to functional ANOVA decomposition, and
                    show improved convergence rates for sparse computation methods. With only a small number of
                    additive low-dimensional terms, we demonstrate
                    the OAK model achieves similar or better predictive performance compared to black-box models,
                    while retaining interpretability
                    </p>
                      <a href="./index.html" onclick="trackOutboundLink(this, 'outbound', 'Xiaoyu');">Xiaoyu Lu<sup></sup></a>,
                      <a href="https://uk.linkedin.com/in/alexis-boukouvalas-9563102" onclick="trackOutboundLink(this, 'outbound', 'Danilo Rezende');">Alexis Boukouvalas</a>,
                      <a href="https://scholar.google.co.uk/citations?user=l8dX3ssAAAAJ&hl=en" onclick="trackOutboundLink(this, 'outbound', 'Dan Rosenbaum');">James Hensman</a>
                    <br>
                    <em><b>ICML 2022.</b></em><br>
                      <a href="https://proceedings.mlr.press/v162/lu22b/lu22b.pdf" onclick="_gaq.push(['_trackEvent', 'downloads', 'functa', 'pdf' ]);">pdf</a>
                      | <a href="./papers/bibtex/functa.bib" onclick="_gaq.push(['_trackEvent', 'downloads', 'functa', 'bibtex' ]);">bibtex</a>
                      | <a href="https://github.com/amzn/orthogonal-additive-gaussian-processes" onclick="_gaq.push(['_trackEvent', 'downloads', 'functa', 'code' ]);">github</a>
                    <br>
                  </td>
                </tr>
                <tr>
                  <td valign="top">
                    <b>Causal Bayesian Optimization</b>
                    <p>
                    <em>Abstract:</em> This paper studies the problem of globally
                    optimizing a variable of interest that is part
                    of a causal model in which a sequence of interventions can be performed. This problem
                    arises in biology, operational research, communications and, more generally, in all fields
                    where the goal is to optimize an output metric of a system of interconnected nodes. Our
                    approach combines ideas from causal inference, uncertainty quantification and sequential decision making. In particular, it generalizes Bayesian optimization, which treats
                    the input variables of the objective function
                    as independent, to scenarios where causal information is available. We show how knowing the causal graph significantly improves
                    the ability to reason about optimal decision
                    making strategies decreasing the optimization cost while avoiding suboptimal solutions.
                    We propose a new algorithm called Causal
                    Bayesian Optimization (cbo). cbo automatically balances two trade-offs: the classical exploration-exploitation and the new
                    observation-intervention, which emerges when
                    combining real interventional data with the
                    estimated intervention effects computed via
                    do-calculus. We demonstrate the practical
                    benefits of this method in a synthetic setting
                    and in two real-world applications.
                    </p>
                      <a href="https://virgiagl.github.io/" onclick="trackOutboundLink(this, 'outbound', 'Virginia');">Virginia Aglietti</a>,
                      <a href="./index.html" onclick="trackOutboundLink(this, 'outbound', 'Xiaoyu');"> Xiaoyu Lu</a>,
                      <a href="https://paleyes.info/" onclick="trackOutboundLink(this, 'outbound', 'Andrei');">Andrei Paleyes</a>,
                      <a href="https://javiergonzalezh.github.io/" onclick="trackOutboundLink(this, 'outbound', 'Javier');">Javier González</a>
                    <br>
                    <em><b>AISTATS 2020.</b></em><br>
                      <a href="https://arxiv.org/pdf/2005.11741.pdf" onclick="_gaq.push(['_trackEvent', 'downloads', 'instaaug', 'pdf' ]);">pdf</a>
                      | <a href="./papers/bibtex/cbo.bib" onclick="_gaq.push(['_trackEvent', 'downloads', 'instaaug', 'bibtex' ]);">bibtex</a>
                    <br>
                  </td>
                </tr>
                <tr>
                  <td valign="top">
                    <b>Structure Mapping for Transferability of Causal Models</b>
                    <p>
                    <em>Abstract:</em> Human beings learn causal models and constantly use them to transfer knowledge between similar environments. We use this intuition to design a transfer-learning framework using object-oriented representations to learn the causal relationships between objects. A learned causal dynamics model can be used to transfer between variants of an environment with exchangeable perceptual features among objects but with the same underlying causal dynamics. We adapt continuous optimization for structure learning techniques to explicitly learn the cause and effects of the actions in an interactive environment and transfer to the target domain by categorization of the objects based on causal knowledge. We demonstrate the advantages of our approach in a gridworld setting by combining causal model-based approach with model-free approach in reinforcement learning.
                    </p>
                      <a href="https://purvapruthi.github.io/" onclick="trackOutboundLink(this, 'outbound', 'Purva');">Purva Pruthi</a>,
                      <a href="https://javiergonzalezh.github.io/" onclick="trackOutboundLink(this, 'outbound', 'Javier');">Javier Gonzlez</a>,
                      <a href="./index.html" onclick="trackOutboundLink(this, 'outbound', 'Xiaoyu');">Xiaoyu Lu</a>,
                      <a href="https://scholar.google.com/citations?user=NTHsaUQAAAAJ&hl=en" onclick="trackOutboundLink(this, 'outbound', 'Yee Whye');">Madalina Fiterau</a>
                    <br>
                    <em>ICML 2020 Inductive Biases, Invariances and
                      Generalization in Reinforcement Learning Workshop.</em>, 2020.<br>
                      <a href="https://arxiv.org/pdf/2007.09445.pdf" onclick="_gaq.push(['_trackEvent', 'downloads', 'pretraining', 'pdf' ]);">pdf</a>
                      | <a href="./papers/bibtex/transfercausal.bib" onclick="_gaq.push(['_trackEvent', 'downloads', 'pretraining', 'bibtex' ]);">bibtex</a>
                    <br>
                  </td>
                </tr>
                <tr>
                  <tr>
                    <td valign="top">
                      <b>FactoredRL: Leveraging factored graphs for deep reinforcement learning</b>
                      <p>
                      <em>Abstract:</em> We propose a simple class of deep reinforcement learning (RL) methods, called FactoredRL, that can leverage factored environment structures to improve the sample efficiency of existing model-based and model-free RL algorithms. In tabular and linear approximation settings, the factored Markov decision process literature has shown exponential improvements in sample efficiency by leveraging factored environment structures. We extend this to deep RL algorithms that use neural networks. For model-based algorithms, we use the factored structure to inform the state transition network architecture and for model-free algorithms we use the factored structure to inform the Q network or the policy network architecture. We demonstrate that doing this significantly improves sample efficiency in both discrete and continuous state-action space settings.
                      </p>
                        <a href="https://www.amazon.science/author/bharathan-balaji" onclick="trackOutboundLink(this, 'outbound', 'Bharathan');"> Bharathan Balaji</a>,
                        <a href="https://www.amazon.science/author/petros-christodoulou" onclick="trackOutboundLink(this, 'outbound', 'Petros');">Petros Christodoulou</a>,
                        <a href="./index.html" onclick="trackOutboundLink(this, 'outbound', 'Xiaoyu');">Xiaoyu Lu</a>,
                        <a href="https://www.amazon.science/author/byungsoo-jeon" onclick="trackOutboundLink(this, 'outbound', 'Byungsoo');">Byungsoo Jeon</a>
                        <a href="https://www.linkedin.com/in/jordan-bell-masterson-43537739/" onclick="trackOutboundLink(this, 'outbound', 'Jordan');">Jordan Bell-Masterson</a>
                      <br>
                      <em>NeurIPS Workshop on Deep Reinforcement Learning.</em>, 2020.<br>
                        <a href="https://assets.amazon.science/35/8c/c6499c644c2c8f19ee8461c917cc/factoredrl-leveraging-factored-graphs-for-deep-reinforcement-learning.pdf" onclick="_gaq.push(['_trackEvent', 'downloads', 'pretraining', 'pdf' ]);">pdf</a>
                        | <a href="./papers/bibtex/factoredrl.bib" onclick="_gaq.push(['_trackEvent', 'downloads', 'pretraining', 'bibtex' ]);">bibtex</a>
                      <br>
                    </td>
                  </tr>
                  <tr>
                  <td valign="top">
                    <b>Structured Variationally Auto-encoded Optimization</b>
                    <p>
                    <em>Abstract:</em> We tackle the problem of optimizing a black-box objective function defined over a highly-structured input space. This problem is ubiquitous in science and engineering. In machine learning, inferring the structure of a neural network or the Automatic Statistician (AS), where the optimal kernel combination for a Gaussian process is selected, are two important examples. We use the \as as a case study to describe our approach, that can be easily generalized to other domains. We propose an Structure Generating Variational Auto-encoder (SG-VAE) to embed the original space of kernel combinations into some low-dimensional continuous manifold where Bayesian optimization (BO) ideas are used. This is possible when structural knowledge of the problem is available, which can be given via a simulator or any other form of generating potentially good solutions. The right exploration-exploitation balance is imposed by propagating into the search the uncertainty of the latent space of the SG-VAE, that is computed using variational inference. The key aspect of our approach is that the SG-VAE can be used to bias the search towards relevant regions, making it suitable for transfer learning tasks. Several experiments in various application domains are used to illustrate the utility and generality of the approach described in this work.
                    </p>
                      <a href="./index.html" onclick="trackOutboundLink(this, 'outbound', 'Xiaoyu');">Xiaoyu Lu</a>,
                      <a href="https://javiergonzalezh.github.io/" onclick="trackOutboundLink(this, 'outbound', 'Javier');">Javier Gonzlez</a>,
                      <a href="https://zhenwendai.github.io/" onclick="trackOutboundLink(this, 'outbound', 'Xiaoyu');">Zhenwen Dai</a>,
                      <a href="https://inverseprobability.com/" onclick="trackOutboundLink(this, 'outbound', 'Neil');">Neil D. Lawrence</a>
                    <br>
                    <em><b>ICML 2018.</b></em><br>
                      <a href="http://proceedings.mlr.press/v80/lu18c/lu18c.pdf" onclick="_gaq.push(['_trackEvent', 'downloads', 'pretraining', 'pdf' ]);">pdf</a>
                      | <a href="./papers/bibtex/vaebo.bib" onclick="_gaq.push(['_trackEvent', 'downloads', 'pretraining', 'bibtex' ]);">bibtex</a>
                    <br>
                  </td>
                </tr>
                <tr>
                  <td valign="top">
                    <b> On Exploration, Exploitation and Learning in Adaptive Importance Sampling</b>
                    <p>
                    <em>Abstract:</em> We study adaptive importance sampling (AIS) as an online learning problem and argue for the importance of the trade-off between exploration and exploitation in this adaptation. Borrowing ideas from the bandits literature, we propose Daisee, a partition-based AIS algorithm. We further introduce a notion of regret for AIS and show that Daisee has O(√T(logT)^(3/4)) cumulative pseudo-regret, where T is the number of iterations. We then extend Daisee to adaptively learn a hierarchical partitioning of the sample space for more efficient sampling and confirm the performance of both algorithms empirically.
                    </p>
                      <a href="./index.html" onclick="trackOutboundLink(this, 'outbound', 'Xiaoyu');">Xiaoyu Lu</a>,
                      <a href="https://www.robots.ox.ac.uk/~twgr/" onclick="trackOutboundLink(this, 'outbound', 'Tom');">Tom Rainforth</a>,
                      <a href="https://yuaanzhou.github.io/" onclick="trackOutboundLink(this, 'outbound', 'Yuan');"> Yuan Zhou</a>,
                      <a href="https://jwvdm.github.io/" onclick="trackOutboundLink(this, 'outbound', 'Jan-Willem');">Jan-Willem van de Meent</a>
                      <a href="http://www.stats.ox.ac.uk/~teh/" onclick="trackOutboundLink(this, 'outbound', 'Yee Whye');">Yee Whye Teh</a>
                    <br>
                    <em><b>arXiv 2018.</b></em><br>
                      <a href="https://arxiv.org/pdf/1810.13296.pdf" onclick="_gaq.push(['_trackEvent', 'downloads', 'pretraining', 'pdf' ]);">pdf</a>
                      | <a href="./papers/bibtex/ais.bib" onclick="_gaq.push(['_trackEvent', 'downloads', 'pretraining', 'bibtex' ]);">bibtex</a>
                    <br>
                  </td>
                </tr>
                <tr>
                  <td valign="top">
                    <b>Inference trees: Adaptive inference with exploration</b>
                    <p>
                    <em>Abstract:</em> We introduce inference trees (ITs), a new class of inference methods that build on ideas from Monte Carlo tree search to perform adaptive sampling in a manner that balances exploration with exploitation, ensures consistency, and alleviates pathologies in existing adaptive methods. ITs adaptively sample from hierarchical partitions of the parameter space, while simultaneously learning these partitions in an online manner. This enables ITs to not only identify regions of high posterior mass, but also maintain uncertainty estimates to track regions where significant posterior mass may have been missed. ITs can be based on any inference method that provides a consistent estimate of the marginal likelihood. They are particularly effective when combined with sequential Monte Carlo, where they capture long-range dependencies and yield improvements beyond proposal adaptation alone.
                    </p>
                      <a href="https://www.robots.ox.ac.uk/~twgr/" onclick="trackOutboundLink(this, 'outbound', 'Tom');">Tom Rainforth</a>,
                      <a href="https://yuaanzhou.github.io/" onclick="trackOutboundLink(this, 'outbound', 'Yuan');"> Yuan Zhou</a>,
                      <a href="./index.html" onclick="trackOutboundLink(this, 'outbound', 'Xiaoyu');">Xiaoyu Lu</a>,
                      <a href="http://www.stats.ox.ac.uk/~teh/" onclick="trackOutboundLink(this, 'outbound', 'Yee Whye');">Yee Whye Teh</a>
                      <a href="https://www.robots.ox.ac.uk/~fwood/" onclick="trackOutboundLink(this, 'outbound', 'Frank');">Frank Wood</a>,
                      <a href="https://www.cs.ox.ac.uk/people/hongseok.yang/Public/Home.html" onclick="trackOutboundLink(this, 'outbound', 'Hongseok');"> Hongseok Yang</a>
                      <a href="https://jwvdm.github.io/" onclick="trackOutboundLink(this, 'outbound', 'Jan-Willem');">Jan-Willem van de Meent</a>
                    <br>
                    <em><b>arXiv 2018.</b></em><br>
                      <a href="https://arxiv.org/pdf/1806.09550v1.pdf" onclick="_gaq.push(['_trackEvent', 'downloads', 'pretraining', 'pdf' ]);">pdf</a>
                      | <a href="./papers/bibtex/inferencetrees.bib" onclick="_gaq.push(['_trackEvent', 'downloads', 'pretraining', 'bibtex' ]);">bibtex</a>
                    <br>
                  </td>
                </tr>
                <tr>
                  <td valign="top">
                    <b>Relativistic Monte Carlo</b>
                    <p>
                    <em>Abstract:</em> Hamiltonian Monte Carlo (HMC) is a popular Markov chain Monte Carlo (MCMC) algorithm that generates proposals for a Metropolis-Hastings algorithm by simulating the dynamics of a Hamiltonian system. However, HMC is sensitive to large time discretizations and performs poorly if there is a mismatch between the spatial geometry of the target distribution and the scales of the momentum distribution. In particular the mass matrix of HMC is hard to tune well. In order to alleviate these problems we propose relativistic Hamiltonian Monte Carlo, a version of HMC based on relativistic dynamics that introduce a maximum velocity on particles. We also derive stochastic gradient versions of the algorithm and show that the resulting algorithms bear interesting relationships to gradient clipping, RMSprop, Adagrad and Adam, popular optimisation methods in deep learning. Based on this, we develop relativistic stochastic gradient descent by taking the zero-temperature limit of relativistic stochastic gradient Hamiltonian Monte Carlo. In experiments we show that the relativistic algorithms perform better than classical Newtonian variants and Adam.
                    </p>
                      <a href="./index.html" onclick="trackOutboundLink(this, 'outbound', 'Xiaoyu');">Xiaoyu Lu</a>,
                      <a href="https://sites.google.com/view/valerioperrone/" onclick="trackOutboundLink(this, 'outbound', 'Valerio');">Valerio Perrone</a>,
                      <a href="https://leonard-hasenclever.github.io/" onclick="trackOutboundLink(this, 'outbound', 'Leonard');">Leonard Hasenclever</a>,
                      <a href="http://www.stats.ox.ac.uk/~teh/" onclick="trackOutboundLink(this, 'outbound', 'Yee Whye');">Yee Whye Teh</a>
                      <a href="https://scholar.google.co.uk/citations?user=WoqSEpYAAAAJ&hl=en" onclick="trackOutboundLink(this, 'outbound', 'Sebastian');">Sebastian J. Vollmer</a>
                    <br>
                    <em><b>AISTATS 2017.</b></em><br>
                      <a href="https://arxiv.org/pdf/1609.04388.pdf" onclick="_gaq.push(['_trackEvent', 'downloads', 'pretraining', 'pdf' ]);">pdf</a>
                      | <a href="./papers/bibtex/rhmc.bib" onclick="_gaq.push(['_trackEvent', 'downloads', 'pretraining', 'bibtex' ]);">bibtex</a>
                    <br>
                  </td>
                </tr>
            </tbody>
          </table>			

            <table border="0" cellspacing="10" cellpadding="2">
              <tbody>                  
                <tr>
                  <td valign="top">
                    <b>Collaborative Filtering with Side Information: a Gaussian Process Perspective</b>
                    <p>
                    <em>Abstract:</em> We tackle the problem of collaborative filtering (CF) with side information,
                      through the lens of Gaussian Process (GP) regression. Driven by the idea of using the kernel 
                      to explicitly model user-item similarities, we formulate the GP in a way that allows the 
                      incorporation of low-rank matrix factorisation, arriving at our model, the Tucker Gaussian Process (TGP). 
                      Consequently, TGP generalises classical Bayesian matrix factorisation models, 
                      and goes beyond them to give a natural and elegant method for incorporating side information, 
                      giving enhanced predictive performance for CF problems. 
                      Moreover we show that it is a novel model for regression, 
                      especially well-suited to grid-structured data and problems 
                      where the dependence on covariates is close to being separable.
                    </p>
                      <a href="https://hyunjik11.github.io/" onclick="trackOutboundLink(this, 'outbound', 'Hyunjik');">Hyunjik Kim</a>,
                      <a href="./index.html" onclick="trackOutboundLink(this, 'outbound', 'Hyunjik');">Xiaoyu Lu</a>,
                      <a href="http://sethrf.com/" onclick="trackOutboundLink(this, 'outbound', 'Seth');">Seth Flaxman</a>,
                      <a href="http://www.stats.ox.ac.uk/~teh/" onclick="trackOutboundLink(this, 'outbound', 'Yee Whye');">Yee Whye Teh</a>
                    <br>
                    <em>ArXiv</em>, 2016.<br>
                      <a href="https://arxiv.org/pdf/1605.07025" onclick="_gaq.push(['_trackEvent', 'downloads', 'tuckergp', 'pdf' ]);">pdf</a>
                      | <a href="./papers/bibtex/tuckergp.bib" onclick="_gaq.push(['_trackEvent', 'downloads', 'tuckergp', 'bibtex' ]);">bibtex</a>
                    <br>
                  </td>
                </tr>
                <tr>
                  <td height="10px"></td>
                </tr>
              </tbody>
            </table>
   
            </tbody>
          </table>
        </div>
      </div>
    </div>

  </body>
</html>
